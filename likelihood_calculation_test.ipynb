{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glasflow is using its own internal version of nflows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyCBC.libutils: pkg-config call failed, setting NO_PKGCONFIG=1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import corner as corner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "\n",
    "from populations.bbh_models import get_models\n",
    "import populations.bbh_models as read_models\n",
    "from populations.utils.flow import NFlow\n",
    "from populations.Flowsclass_dev import FlowModel\n",
    "from populations import gw_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the pop synth file functions\n",
    "def get_model_keys(path):\n",
    "    alpha_val = '10'\n",
    "    all_models = []\n",
    "    models = []\n",
    "    def find_submodels(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            all_models.append(name.rsplit('/', 1)[0])\n",
    "            \n",
    "    f = h5py.File(path, 'r')\n",
    "    f.visititems(find_submodels)\n",
    "    # get all unique models\n",
    "    all_models = sorted(list(set(all_models)))\n",
    "    f.close()\n",
    "\n",
    "    # use only models with given alpha value\n",
    "    for model in all_models:\n",
    "        if 'alpha' in model:\n",
    "            if 'alpha'+alpha_val in model:\n",
    "                models.append('/'+model)\n",
    "        else:\n",
    "            models.append('/' + model)\n",
    "    return(np.split(np.array(models), 5))\n",
    "\n",
    "def get_model_keys_CE(path):\n",
    "    all_models = []\n",
    "    models = []\n",
    "    def find_submodels(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            all_models.append(name.rsplit('/', 1)[0])\n",
    "            \n",
    "    f = h5py.File(path, 'r')\n",
    "    f.visititems(find_submodels)\n",
    "    # get all unique models\n",
    "    all_models = sorted(list(set(all_models)))\n",
    "    return(np.split(np.array(models), 4))\n",
    "\n",
    "def read_hdf5(path, all_alpha=False):\n",
    "    if all_alpha:\n",
    "        popsynth_outputs = {}\n",
    "        models = np.asarray(get_model_keys_CE(path))\n",
    "        for i in range(models.shape[0]):\n",
    "            for j in range(models.shape[1]):\n",
    "                popsynth_outputs[i,j]=pd.read_hdf(path, key=models[i,j])\n",
    "    else:\n",
    "        popsynth_outputs = {}\n",
    "        models = np.asarray(get_model_keys(path))\n",
    "        for i in range(models.shape[0]):\n",
    "            for j in range(models.shape[1]):\n",
    "                popsynth_outputs[i,j]=pd.read_hdf(path, key=models[i,j])\n",
    "\n",
    "    return(popsynth_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obs = np.random.rand(100,46,4)\\nobs[:,:,0] *=param_bounds[0,1]\\nobs[:,:,1] *=param_bounds[1,1]\\nobs[:,:,2] -= 0.5\\nobs[:,:,2] *=param_bounds[2,1]*2\\nobs[:,:,3] *=param_bounds[3,1]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = ['mchirp','q', 'chieff', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='/Users/stormcolloms/Documents/PhD/Project_work/OneChannel_Flows/models_reduced.hdf5'\n",
    "gw_path = '/Users/stormcolloms/Documents/PhD/Project_work/AMAZE_model_selection/gw_events'\n",
    "observations, obsdata, p_theta, events = gw_obs.generate_observations(params, gw_path, \\\n",
    "                                            100, 'posteriors', None)\n",
    "\n",
    "popsynth_outputs = read_hdf5(file_path, True)\n",
    "flow = FlowModel.from_samples('CE', popsynth_outputs, params)\n",
    "flow.load_model('/Users/stormcolloms/Documents/PhD/Project_work/AMAZE_model_selection/flow_models/', 'CE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations, obsdata, p_theta, events = gw_obs.generate_observations(params, gw_path, \\\n",
    "                                            10000, 'posteriors', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.33316706e-14 6.74989417e-15 1.40664918e-13 ... 3.05537262e-11\n",
      "  8.97486126e-15 7.74752441e-14]\n",
      " [3.23475913e-29 1.46733039e-17 1.80772845e-16 ... 2.73923155e-18\n",
      "  2.22274049e-14 5.38213679e-13]\n",
      " [3.98253396e-05 3.65201086e-05 1.20607823e-04 ... 2.92698824e-05\n",
      "  4.12492082e-05 9.04306853e-06]\n",
      " ...\n",
      " [3.02265789e-07 1.19038316e-06 2.99648968e-06 ... 5.78707443e-07\n",
      "  2.97906854e-06 1.30976866e-06]\n",
      " [1.63152383e-13 1.47788601e-13 6.22116247e-12 ... 2.62943348e-11\n",
      "  5.51899759e-12 4.59400747e-13]\n",
      " [8.04975357e-12 7.35457736e-23 1.25554974e-11 ... 4.32804573e-12\n",
      "  5.73459292e-12 1.06214404e-11]]\n"
     ]
    }
   ],
   "source": [
    "likelihoods = flow(obsdata,[3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.07910525e+00 3.69565218e-01 7.71533639e-03 1.36051353e-01\n",
      " 1.90474706e+02 4.78260870e-01 8.99927727e-10 2.13956522e+02\n",
      " 1.99978315e+02 9.80728273e+02 1.84347904e+01 1.58913043e+01\n",
      " 6.22655603e-01 2.55290761e-02 3.93231552e-01 1.38590597e-12\n",
      " 4.56396097e-01 2.81134151e+00 1.34475989e-02 6.47550878e-11\n",
      " 4.90044719e-10 3.52906395e-08 4.41026327e-01 8.27332347e-05\n",
      " 1.77718307e+01 2.60884192e-01 5.06505807e+01 1.06847871e+02\n",
      " 6.12791618e+01 3.85217796e+01 5.74991096e-02 4.95652183e+00\n",
      " 1.28919210e-01 2.37869368e-09 5.86308940e-09 2.02520414e-01\n",
      " 1.84717283e-01 1.76326087e+02 1.63260823e-05 2.17391304e+02\n",
      " 2.81224248e+02 2.52174028e+00 3.13790051e-02 8.37177008e-04\n",
      " 2.42412306e-09 1.12062876e-09]\n"
     ]
    }
   ],
   "source": [
    "print(likelihoods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('amaze')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40f4eedd3c2b0a4cf443053300595e4c410b663f293e84798d1742802fb2c7c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
