{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glasflow is using its own internal version of nflows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyCBC.libutils: pkg-config call failed, setting NO_PKGCONFIG=1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import corner as corner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "\n",
    "from populations.bbh_models import get_models\n",
    "import populations.bbh_models as read_models\n",
    "from populations.utils.flow import NFlow\n",
    "from populations.Flowsclass_dev import FlowModel\n",
    "from populations import gw_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the pop synth file functions\n",
    "def get_model_keys(path):\n",
    "    alpha_val = '10'\n",
    "    all_models = []\n",
    "    models = []\n",
    "    def find_submodels(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            all_models.append(name.rsplit('/', 1)[0])\n",
    "            \n",
    "    f = h5py.File(path, 'r')\n",
    "    f.visititems(find_submodels)\n",
    "    # get all unique models\n",
    "    all_models = sorted(list(set(all_models)))\n",
    "    f.close()\n",
    "\n",
    "    # use only models with given alpha value\n",
    "    for model in all_models:\n",
    "        if 'alpha' in model:\n",
    "            if 'alpha'+alpha_val in model:\n",
    "                models.append('/'+model)\n",
    "        else:\n",
    "            models.append('/' + model)\n",
    "    return(np.split(np.array(models), 5))\n",
    "\n",
    "def get_model_keys_CE(path):\n",
    "    all_models = []\n",
    "    models = []\n",
    "    def find_submodels(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            all_models.append(name.rsplit('/', 1)[0])\n",
    "            \n",
    "    f = h5py.File(path, 'r')\n",
    "    f.visititems(find_submodels)\n",
    "    # get all unique models\n",
    "    all_models = sorted(list(set(all_models)))\n",
    "    return(np.split(np.array(models), 4))\n",
    "\n",
    "def read_hdf5(path, all_alpha=False):\n",
    "    if all_alpha:\n",
    "        popsynth_outputs = {}\n",
    "        models = np.asarray(get_model_keys_CE(path))\n",
    "        for i in range(models.shape[0]):\n",
    "            for j in range(models.shape[1]):\n",
    "                popsynth_outputs[i,j]=pd.read_hdf(path, key=models[i,j])\n",
    "    else:\n",
    "        popsynth_outputs = {}\n",
    "        models = np.asarray(get_model_keys(path))\n",
    "        for i in range(models.shape[0]):\n",
    "            for j in range(models.shape[1]):\n",
    "                popsynth_outputs[i,j]=pd.read_hdf(path, key=models[i,j])\n",
    "\n",
    "    return(popsynth_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obs = np.random.rand(100,46,4)\\nobs[:,:,0] *=param_bounds[0,1]\\nobs[:,:,1] *=param_bounds[1,1]\\nobs[:,:,2] -= 0.5\\nobs[:,:,2] *=param_bounds[2,1]*2\\nobs[:,:,3] *=param_bounds[3,1]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params = ['mchirp','q', 'chieff', 'z']\n",
    "param_bounds = np.array([[0,100], [0,1], [-1,1], [0,10]])\n",
    "\"\"\"obs = np.random.rand(100,46,4)\n",
    "obs[:,:,0] *=param_bounds[0,1]\n",
    "obs[:,:,1] *=param_bounds[1,1]\n",
    "obs[:,:,2] -= 0.5\n",
    "obs[:,:,2] *=param_bounds[2,1]*2\n",
    "obs[:,:,3] *=param_bounds[3,1]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='/Users/stormcolloms/Documents/PhD/Project_work/OneChannel_Flows/models_reduced.hdf5'\n",
    "gw_path = '/Users/stormcolloms/Documents/PhD/Project_work/AMAZE_model_selection/gw_events'\n",
    "observations, obsdata, p_theta, events = gw_obs.generate_observations(params, gw_path, \\\n",
    "                                            100, 'posteriors', None)\n",
    "\n",
    "popsynth_outputs = read_hdf5(file_path, True)\n",
    "flow = FlowModel.from_samples('CE', popsynth_outputs, params)\n",
    "flow.load_model('/Users/stormcolloms/Documents/PhD/Project_work/AMAZE_model_selection/flow_models/', 'CE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 100, 4)\n",
      "(46, 100, 4)\n",
      "(46, 100)\n"
     ]
    }
   ],
   "source": [
    "likelihoods = flow(obsdata,[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.60597305e-01 9.16298964e-02 9.90929334e-02 1.69736949e-01\n",
      " 1.82608948e+00 9.45666301e-02 1.12873732e-01 2.17391304e+00\n",
      " 2.00000005e+00 5.83961924e+00 5.19426177e-01 2.90160875e-01\n",
      " 1.76031913e+00 1.88963299e-02 2.24207219e-01 1.40553681e-02\n",
      " 8.55617637e+00 1.15680260e+00 4.13015485e-01 1.82665704e-01\n",
      " 7.95931797e-02 1.57647617e+00 7.81326177e+00 2.64489054e+00\n",
      " 2.12408962e+00 1.99639153e+00 5.62378744e-01 1.12325693e+00\n",
      " 6.20778301e-01 1.93235872e+00 2.59999542e-01 3.84047012e-01\n",
      " 1.38971383e-01 1.41022945e+00 1.72365618e-01 2.70470812e-01\n",
      " 1.43294777e-01 1.76086972e+00 1.19361830e+00 2.17391304e+00\n",
      " 5.02926987e-01 6.09310640e-01 3.44531316e-01 1.25363955e-06\n",
      " 5.09206629e-01 8.98295514e-02]\n"
     ]
    }
   ],
   "source": [
    "print(likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('amaze')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40f4eedd3c2b0a4cf443053300595e4c410b663f293e84798d1742802fb2c7c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
