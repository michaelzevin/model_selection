#!/usr/bin/env python

#######################
### MODEL SELECTION ###
#######################

# --- Import packages --- #
import sys
import argparse
import h5py
import warnings

import numpy as np
import pandas as pd
import scipy.stats

from populations import bbh_models, gw_obs
from sample import sample
from plot import msplot

VERBOSE=True
MAKE_PLOTS=True

# --- Argument handling --- #
argp = argparse.ArgumentParser()
argp.add_argument("-d", "--dirpath", type=str, required=True, help="Sets the \
directory path where the models are living. Models must be stored as an hdf \
file with different keys storing the information about different channels. \
The name of the hdf file is the name of the population (e.g. 'chi01.hdf'.")
argp.add_argument("-m", "--model0", type=str, required=True, help="Sets the \
'true' model from which mock observations are drawn. If 'gwobs', will use \
the actual GW observations.")
argp.add_argument("-gw", "--gwpath", type=str, help="Sets the path for where \
the GW samples are living. Default=None.")
argp.add_argument("-b", "--beta", nargs="*", help="Chooses the branching \
fraction. The number provided is the fraction of systems that come from each \
channel in alphabetical order. Must be set if gwobs not used. Can provide \
Nchannel values (which must sum to unity) or Nchannel-1 values (which must be \
less than 1.0, and the last branching fraction is inferred). Default=None.")
argp.add_argument("-n", "--Nobs", type=int, help="Number of mock observations \
to be taken from the model. Must be set if gwobs not used. Default=None.")
argp.add_argument("-N", "--Nsamps", type=int, default=100, help="Number of \
samples to be drawn from the posterior distributions and used to construct \
the KDE models. Default=100.")
argp.add_argument("-w", "--weights", type=str, help="Name of column in \
dataframe of detection probabilities. Default=None.")
argp.add_argument("-u", "--uncertainty", type=str, help="Smear out observations in \
a mocked up attempt at non-delta function observation posteriors. For GW obs, \
you can choose to smear using the actual posterior samples ('posteriors'), or \
from a mock gaussian with the mean and sigma of observations ('gaussian'). \
For mock observations, you can choose to smear according to the average \
spread in parameters from current GW observations ('gwevents'), or use a gaussian \
with an SNR-dependent sigma ('snr'). Default=None.")
argp.add_argument("-p", "--params", nargs="+", default="mchirp", help=\
"Specifies the parameters you wish to use in the inference. Default=mchirp.")
argp.add_argument("-sm", "--spinmag", type=str, help="Define the spin \
magnitude distribution you wish to use. Required for using spin parameters in \
populations where the spin magnitude is not specified. Default is None.")
argp.add_argument("-S", "--save-samples", action="store_true", help="Save all \
the samples rather than just the summary statistics. Default is False.")
argp.add_argument("-E", "--evidence", action="store_true", help="Determines \
whether or not to calculate the evidence for each submodel using \
thermodynamic integration. Default is False.")
argp.add_argument("-rs", "--random-seed", type=int, help="Use this to set the \
random seed. Default=None.")
argp.add_argument("--name", type=str, help="Use this as the stem for all file \
output. Default=None.")
args = argp.parse_args()

# --- Set random seed
if args.random_seed:
    np.random.seed(args.random_seed)

# --- Load in models/kdemodels into dict structure: models[model][channel]
models, kde_models = bbh_models.get_models(args.dirpath, args.params, \
                        args.spinmag, weighting=args.weights)
model_names = list(models.keys())
model_names.sort()
channels = list(models[list(models.keys())[0]].keys())
channels.sort()
params = args.params

# see if we're using GW observations
gwobs = True if args.model0=='gwobs' else False

if VERBOSE:
    print("Formation channels: " + ", ".join(channels))
    print("Astrophysical models: " + ", ".join(model_names))
    print("Parameters for inference: " + ", ".join(params))
    print("")



# --- Perform some checks to make sure things are compatible

# check to see if the models have the same formation channels
for model in model_names:
    if set(models[model].keys()) != set(channels):
        raise ValueError("Different models have differing formation channels! \
Check your hdf keys...")

# check that a value of beta is provided if gwobs not specified
if not gwobs:
    if not args.beta:
        raise ValueError("You need to either specify branching fractions or \
choose to instead use GW observations!")

# check that the true model provided is valid if gwobs not specified
if (args.model0 not in model_names and not gwobs):
    raise ValueError("The true model you specified ({0:s}) is not one of the \
models in {1:s} directory!".format(args.model0, args.dirpath))

# check that Nobs was specified if not using gwobs
if not gwobs and not args.Nobs:
    raise ValueError("You need to specify and number of observations to be \
drawn from the 'true' model if not using GW observations!")

# check that valid measurement uncertainty is specified
if gwobs:
    if args.uncertainty not in ["gaussian", "posteriors"]:
        raise ValueError("Unspecified measurement uncertainty procedure when using GW \
observations: {0:s}".format(args.measurement_uncertainty))
else:
    if args.uncertainty not in ["gwevents", "snr"]:
        raise ValueError("Unspecified measurement uncertainty procedure when using mock \
observations: {0:s}".format(args.measurement_uncertainty))

# parse the branching ratio values and check for errors
if not gwobs:
    betas = [float(x) for x in args.beta]
    if (len(betas) != len(channels)) and (len(betas) != len(channels)-1):
        raise ValueError("Must specify {0:d} or {1:d} branching fractions, \
you provided {2:d}!".format(len(channels)-1, len(channels), len(betas)))
    if np.sum(betas) > 1.0:
        raise ValueError("Branching fractions must sum to less than or equal \
to 1.0, yours sum to {0:0.2f}!".format(np.sum(betas)))
    if (len(betas) == len(channels)) and (np.sum(betas) != 1.0):
        raise ValueError("If you provide the same number of branching \
fractions as channels, they must sum to exactly 1.0 (yours sum to \
{0:0.2f})!".format(np.sum(betas)))

    if len(betas) != len(channels):
        betas.append(1.0 - np.sum(betas))

# --- If model0 specified, save relative fractions for each KDE model, 
# and store model0
if not gwobs:
    if VERBOSE:
        print("Saving relative fractions and storing true model...\n")

    for model in model_names:
        # since channels are sorted alphabetically, the first channel has 
        # branching fraction beta
        for idx, (channel, beta) in enumerate(zip(channels, betas)):
            kde_models[model][channel].rel_frac(beta)
            if (model == args.model0):
                model0 = kde_models[model]
                if VERBOSE:
                    if idx==0:
                        print("'{0:s}' set as true model".format(model))
                        print("  model range:")
                    print("    {0:s} (beta={1:0.2f})".format(channel, beta))
                    for param in args.params:
                        print("      {0:s}: {1:0.2f} - {2:0.2f}".format(param,\
                                models[args.model0][channel][param].min(),\
                                models[args.model0][channel][param].max()))
                    if idx==len(betas)-1:
                        print("")


# --- Generate observations ([observations, params, samples])
if VERBOSE:
    print("Generating observations...\n")

# Calls gw_obs.py if argument is passed
if gwobs:
    model0=None
    obsdata, events = gw_obs.generate_observations(params, args.gwpath, \
                                            args.Nsamps, args.uncertainty)
    if VERBOSE:
        print("Using the following {0:d} GW observations for \
inference:".format(len(events)))
        print(*events, sep=', ')
        print("")

else:
    if VERBOSE:
        print("Drawing {0:d} observations from the true \
model...\n".format(int(args.Nobs)))
    for idx, channel in enumerate(model0):
        # first check that the branching fractions * Nobs are integers
        if not (args.Nobs*model0[channel]._rel_frac).is_integer():
            warnings.warn('Number of observations is not divisble by branching fractions, this may result in drawing a number of samples slighty different than what was specified!')
        if idx==0:
            Nobs_per_channel = int(np.round(args.Nobs * model0[channel]._rel_frac))
            obsdata = model0[channel].generate_observations(Nobs_per_channel, \
                                                args.Nsamps, args.uncertainty)
        else:
            Nobs_per_channel = int(np.round(args.Nobs * model0[channel]._rel_frac))
            obsdata = np.concatenate((obsdata, \
                  model0[channel].generate_observations(Nobs_per_channel, \
                                            args.Nsamps, args.uncertainty)))


# Plot the KDEs and observations
if MAKE_PLOTS==True:
    print("Plotting marginalized KDE models...\n")
    msplot.plot_1D_kdemodels(kde_models, params, obsdata, model0, \
                name=args.name, plot_obs=True, plot_obs_samples=False)


# --- Freeze sample evaluations in each model. 
# This is time consuming, but only needs to be done once for each KDE model, 
# so we don't need to recompute p_model(data) over and over again when the 
# observation values aren't going to change. 
# Lower the number of samples per observation to speed this up.
if VERBOSE:
    print("Freezing sample evaluations in their respective models...")
for model in model_names:
    for channel in channels:
        if VERBOSE:
            print("  {0:s}, {1:s}".format(model, channel))
        kde_models[model][channel].freeze(obsdata)
if VERBOSE:
    print("Done freezing KDE evaluations of observations!\n")



# --- Do the sampling!

sampler = sample.Sampler(model_names, channels)
sampler.sample(kde_models, obsdata)
samples = sampler.samples
lnprb = sampler.lnprb


# Plot samples and histograms of betas per model
if MAKE_PLOTS==True:
    print("Plotting samples...\n")
    msplot.plot_samples(samples, model_names, channels, model0, name=args.name)


# reshape to have all steps from all walkers in a single dimension
# (note that we added a dim for the last beta that we synthesized)
samples = samples.reshape((sampler.nwalkers * sampler.Nsteps_final, \
                                sampler.ndim+1))
lnprb = lnprb.reshape((sampler.nwalkers * sampler.Nsteps_final))

# Parse out the model index
smdl_counts = np.floor(samples[:,0]).astype(int)

# Print summary info about the sampling
if VERBOSE:
    print("Sample breakdown:")
    for smdl_idx, smdl in enumerate(model_names):
        counts = len(smdl_counts[smdl_counts == smdl_idx])
        locs = np.where(smdl_counts==smdl_idx)
        recovered_betas = {}
        for cidx, channel in enumerate(channels):
            if len(locs[0]) > 0:
                beta = samples[:,(cidx+1)][locs].mean()
                beta = round(beta, 2)
            else:
                beta = np.nan
            recovered_betas[channel] = beta
        print("  Model {0:s} ({1:d}): {2:d} samples, \
betas={3}".format(smdl, smdl_idx, counts, list(recovered_betas.items())))
    print("")


# --- Calculate the evidence, if specified
if args.evidence:
    if VERBOSE:
        print("Calculating evidence for each submodel...")
    smdl_samplers={}
    for smdl in model_names:
        if VERBOSE:
            print("Model {0:s}:".format(smdl))
        evidence_sampler = sample.Sampler(model_names, channels, smdl=smdl)
        evidence_sampler.sample(kde_models, obsdata)
        smdl_samplers[smdl] = evidence_sampler
        if VERBOSE:
            print("  {0:s} log evidence: {1:0.3f}\n".format(smdl,\
                               evidence_sampler.lnZ))




# --- Save samples

if args.save_samples:
    if args.name:
        fname = "output_" + args.name + ".hdf5"
    else:
        fname = "output.hdf5"

    if VERBOSE:
        print("Saving information to '{0:s}'...\n".format(fname))

    hfile = h5py.File(fname, "w")
    bsgrp = hfile.create_group("model_selection")

    # add model0 attribute
    if args.model0=='gwobs':
        info = np.append([str(args.model0)], [*events])
    else:
        info = np.append([str(args.model0)], \
            [*[key+': '+str(model0[key]._rel_frac) for key in model0.keys()]])
    info = [x.encode('utf-8') for x in info]
    bsgrp.attrs["model0_params"] = info

    # add argument attribute
    arguments = sys.argv[1:]
    arguments = [x.encode('utf-8') for x in arguments]
    bsgrp.attrs["args"] = arguments

    # save observations dataset
    bsgrp.create_dataset("observations", data=obsdata)

    # create subgroup for samples
    group = bsgrp.create_group("samples")
    labels = ["model_idx"] + ["beta_%s" % c for c in channels]
    group.attrs["inference_params"] = labels

    # synthesize last beta, since they sum to unity
    for lbl, d in zip(labels, samples.T):
        group.create_dataset(lbl, data=d)
    hfile.close()

