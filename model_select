#!/usr/bin/env python

#######################
### MODEL SELECTION ###
#######################

# --- Import packages --- #
import sys
import argparse
import h5py
import warnings
from functools import reduce
import operator
from copy import deepcopy
import pdb

import numpy as np
import pandas as pd
import scipy.stats

from populations import bbh_models, gw_obs
from sample import sample
from plot import msplot

# --- Argument handling --- #
argp = argparse.ArgumentParser()
argp.add_argument("-f", "--file-path", type=str, required=True, help="Path to where the population models are living. Models should be stored in hdf5 format, with the channel as the base group, and model parameters as subgroups (e.g., 'CE/chi01/alpha0.5').")
argp.add_argument("-psd", "--psd-path", type=str, required=True, help="Path to directory with PSD files, saved in same format as Observing Scenarios data release.")
argp.add_argument("-m", "--model0", type=str, required=True, help="Sets the 'true' model from which mock observations are drawn. When there are multiple parameters in the submodel, separate with '/' (e.g., 'chi00/alpha5'). If 'gwobs', will use the actual GW observations.")
argp.add_argument("-gw", "--gwpath", type=str, help="Sets the path for where the GW samples are living. Necessary if model0='gwobs'. Default=None.")
argp.add_argument("-c", "--specific-channels", nargs="+", help="Specifies the formation channels you wish to consider in the inference. If 'None', will use all channels in the hdf5 file. Default=None.")
argp.add_argument("-b", "--beta", nargs="*", help="Sets the branching fraction for mock observations. The number provided is the fraction of systems that come from each channel in alphabetical order. Must be set if gwobs not used. Can provide Nchannel values (which must sum to unity) or Nchannel-1 values (which must be less than 1.0, and the last branching fraction is inferred). Default=None.")
argp.add_argument("-p", "--params", nargs="+", default="mchirp", help="Specifies the parameters you wish to use in the inference. Default=mchirp.")
argp.add_argument("-n", "--Nobs", type=int, help="Number of mock observations to be taken from the mixture model. Must be set if gwobs not used. Default=None.")
argp.add_argument("-N", "--Nsamps", type=int, default=100, help="Number of samples to be drawn from the posterior distributions and used to construct the KDE models. Default=100.")
argp.add_argument("--sensitivity", type=str, help="Name of column in dataframe of detection probabilities, which should have the same name as the network sensitivity and configuration you wish to use. This is used to construct a 'detection-weighted' kde. These weights have the same name as the network sensitivity from the LVC Observing Scenarios, and have '_network' appended if using a 3-detector configuration. Default=None.")
argp.add_argument("--uncertainty", type=str, help="Smear out observations in a mocked up attempt at non-delta function observation posteriors. For GW obs, you can choose to smear using the actual posterior samples ('posteriors'), or from a mock gaussian with the mean and sigma of observations ('gaussian'). For mock observations, you can choose to smear according to the average spread in parameters from current GW observations ('gwevents'), or use a gaussian with an SNR-dependent sigma ('snr'). Default=None.")
argp.add_argument("--rate-prior", action="store_true", help="Uses predicted rates from population models as priors. WARNING: still in beta. Default=False.")
argp.add_argument("--spinmag", type=str, help="Define the spin magnitude distribution you wish to use. Required for using spin parameters in populations where the spin magnitude is not specified. Default is None.")
argp.add_argument("--make-plots", action="store_true", help="Determines whether to make accompanying plots. Default is False.")
argp.add_argument("-V", "--verbose", action="store_true", help="Determines whether to be verbose in the code. Default is False.")
argp.add_argument("-S", "--save-samples", action="store_true", help="Save all the samples rather than just the summary statistics. Default is False.")
argp.add_argument("-E", "--evidence", action="store_true", help="Determines whether or not to calculate the evidence for each submodel using thermodynamic integration. WARNING: still in beta. Default is False.")
argp.add_argument("-rs", "--random-seed", type=int, help="Use this to set the random seed. Default=None.")
argp.add_argument("--name", type=str, help="Use this as the stem for all file output. Default=None.")
args = argp.parse_args()

# --- Set random seed
if args.random_seed:
    np.random.seed(args.random_seed)

# --- Save certain boolean arguments
verbose=args.verbose
make_plots=args.make_plots
# see if we're using GW observations
gwobs = True if args.model0=='gwobs' else False

# --- Useful functions for accessing items in dictionary
def getFromDict(dataDict, mapList):
    return reduce(operator.getitem, mapList, dataDict)
def setInDict(dataDict, mapList, value):
    getFromDict(dataDict, mapList[:-1])[mapList[-1]] = value

# --- Load in models/kdemodels into dict structure: models[model][channel]
# `normalize` argument normalizes KDEs on unit cube
model_names, kde_models, = bbh_models.get_models(args.file_path, args.specific_channels, args.params, spin_distr=args.spinmag, sensitivity=args.sensitivity, normalize=False, verbose=verbose)
model_names.sort()
channels = sorted(list(kde_models.keys()))
params = args.params
hyperparams = sorted(list(set([x.split('/', 1)[1] for x in model_names])))
Nhyper = np.max([len(x.split('/')) for x in hyperparams])

# create dict for the hyperparameters at each level
hyperparam_dict  = {}
hyperidx=0
while hyperidx < Nhyper:
    hyperidx_with_Nhyper = np.argwhere(np.asarray([len(x.split('/')) for x in hyperparams])>hyperidx).flatten()
    hyperparams_at_level = sorted(set([x.split('/')[hyperidx] for x in np.asarray(hyperparams)[hyperidx_with_Nhyper]]))
    hyperparam_dict[hyperidx] = hyperparams_at_level
    hyperidx += 1

if verbose:
    print("")
    print("Formation channels: " + ", ".join(channels))
    print("Astrophysical models: " + ", ".join(model_names))
    print("Parameters for inference: " + ", ".join(params))
    print("")


# --- Perform some checks to make sure things are compatible

# check that a value of beta is provided if gwobs not specified
if not gwobs:
    if not args.beta:
        raise ValueError("You need to either specify branching fractions or choose to instead use GW observations!")

# check that the true model provided is valid if gwobs not specified
highest_smdl_ctr=0
for channel in channels:
    base_smdls = [s.split('/')[1] for s in model_names if channel+'/' in s]
    highest_smdls = [s.split('/')[-1] for s in model_names if channel+'/' in s]
    # make sure base model is shared across channels
    if (args.model0.split('/')[0] not in base_smdls and not gwobs):
        raise ValueError("The true model you specified ({0:s}) is not one of the models in {1:s} directory!".format(args.model0, args.file_path))
    # make sure highest level model is given in at least one channel
    if (args.model0.split('/')[-1] in highest_smdls):
        highest_smdl_ctr+=1
if (highest_smdl_ctr==0 and not gwobs):
    raise ValueError("The highest level of the true model you specified ({0:s}) is not used in any of your models!".format(args.model0))

# ensure that the number of hyperparameters in each channel is the same depth
for channel in channels:
    channel_smdls = [x for x in model_names if channel+'/' in x]
    Nlevels_in_channel = [len(x.split('/')) for x in channel_smdls]
    if not all(x == Nlevels_in_channel[0] for x in Nlevels_in_channel):
        raise ValueError("The formation channel '{0:s}' does not have the same hierarchical levels of hyperparameters across submodels: {1:s}".format(channel, ','.join(channel_smdls)))

# ensure that models at each level are consistent across formation channels
i=1 #start at 1, which will be the highest-level hyperparameter since the formation channel is the first parameter
Nhyper_per_model = [len(x.split('/'))-1 for x in model_names]
while i <= Nhyper:
    models_at_hyperlevel = np.asarray(model_names)[np.asarray(Nhyper_per_model) >= i]
    hyper_set = sorted(set([x.split('/')[i] for x in models_at_hyperlevel]))
    for channel in channels:
        channel_smdls = [x for x in models_at_hyperlevel if channel+'/' in x]
        if len(channel_smdls) > 0:
            channel_set = sorted(set([x.split('/')[i] for x in channel_smdls]))
            if sorted(hyper_set) != sorted(channel_set):
                raise ValueError("At hyperparameter level {0:d}, the formation channel {1:s} does not have the same hyperparameters as the rest of the models (all models: {2:s}, {1:s}: {3:s}".format(i, channel, ','.join(hyper_set), ','.join(channel_set)))
    i += 1

# check that Nobs was specified if not using gwobs
if not gwobs and not args.Nobs:
    raise ValueError("You need to specify and number of observations to be drawn from the 'true' model if not using GW observations!")

# check that valid measurement uncertainty is specified
if gwobs:
    valid_uncertainties = ["gaussian", "posteriors"]
    if args.uncertainty not in valid_uncertainties:
        raise ValueError("Unspecified measurement uncertainty procedure when using GW observations: '{0:s}' (valid uncertainties: {1:s})".format(args.uncertainty, ', '.join(valid_uncertainties)))
else:
    valid_uncertainties = ["gwevents", "snr"]
    if args.uncertainty not in valid_uncertainties:
        raise ValueError("Unspecified measurement uncertainty procedure when using mock observations: '{0:s}' (valid uncertainties: {1:s})".format(args.uncertainty, ', '.join(valid_uncertainties)))

# parse the branching ratio values and check for errors
if not gwobs:
    betas = [float(x) for x in args.beta]
    if (len(betas) != len(channels)) and (len(betas) != len(channels)-1):
        raise ValueError("Must specify {0:d} or {1:d} branching fractions, you provided {2:d}!".format(len(channels)-1, len(channels), len(betas)))
    if np.sum(betas) > 1.0:
        raise ValueError("Branching fractions must sum to less than or equal to 1.0, yours sum to {0:0.2f}!".format(np.sum(betas)))
    if (len(betas) == len(channels)) and (np.sum(betas) != 1.0):
        raise ValueError("If you provide the same number of branching fractions as channels, they must sum to exactly 1.0 (yours sum to {0:0.2f})!".format(np.sum(betas)))

    if len(betas) != len(channels):
        betas.append(1.0 - np.sum(betas))

# --- If model0 specified, save relative fractions for each KDE model, and store model0
if not gwobs:
    if verbose:
        print("Saving relative fractions and storing true model...\n")

    model0 = {}
    # since channels are sorted alphabetically, branching fractions are defined in the same order
    for idx, channel in enumerate(channels):
        channel_mdls = [x for x in model_names if channel+'/' in x]
        for model in channel_mdls:
            smdl = model.split('/',1)[1]
            beta = betas[channels.index(channel)]
            # store relative fraction
            getFromDict(kde_models, model.split('/')).rel_frac(beta)
            # print info about model0
            if (smdl in args.model0):
                model0[channel] = getFromDict(kde_models, model.split('/'))
                if verbose:
                    if idx==0:
                        print("'{0:s}' set as true model".format(args.model0))
                        print("  model range:")
                    print("    {0:s} ({1:s}, beta={2:0.2f})".format(channel, smdl, beta))
                    for param in args.params:
                        print("      {0:s}: {1:0.3f} - {2:0.3f}".format(param,\
                                getFromDict(kde_models, model.split('/')).sample_range[param][0],\
                                getFromDict(kde_models, model.split('/')).sample_range[param][1]))
                    if idx==len(betas)-1:
                        print("")

# --- Generate observations ([observations, params, samples])
if verbose:
    print("Generating observations...\n")

# Calls gw_obs.py to generate samples if argument is passed
if gwobs:
    model0=None
    observations, obsdata, events = gw_obs.generate_observations(params, args.gwpath, \
                                            args.Nsamps, args.uncertainty)
    if verbose:
        print("Using the following {0:d} GW observations for \
inference:".format(len(events)))
        print(*events, sep=', ')
        print("")

else:
    if verbose:
        print("Drawing {0:d} observations from the true model...\n".format(int(args.Nobs)))
    for idx, channel in enumerate(model0):
        # first check that the branching fractions * Nobs are integers
        if not (args.Nobs*model0[channel].rel_frac).is_integer():
            warnings.warn('Number of observations is not divisble by branching fractions, this may result in drawing a number of samples slighty different than what was specified!')
        Nobs_per_channel = int(np.round(args.Nobs * model0[channel].rel_frac))
        if idx==0:
            observations = model0[channel].generate_observations(Nobs_per_channel, \
                detector=args.sensitivity, psd_path=args.psd_path, from_detectable=True)
            obsdata = model0[channel].measurement_uncertainty(args.Nsamps, \
                args.uncertainty, observation_noise=True)
        else:
            observations = np.concatenate((observations, \
                model0[channel].generate_observations(Nobs_per_channel, \
                detector=args.sensitivity, psd_path=args.psd_path, from_detectable=True)))
            obsdata = np.concatenate((obsdata, \
                model0[channel].measurement_uncertainty(args.Nsamps, \
                args.uncertainty, observation_noise=True)))


# Plot the KDEs and observations
if make_plots==True:
    print("Plotting marginalized KDE models...")
    msplot.plot_1D_kdemodels(model_names, kde_models, params, observations, obsdata, \
           model0, name=args.name, fixed_vals=['alpha10'], plot_obs=True, plot_obs_samples=False)
    print("")


# --- Freeze sample evaluations in each model. 
# This is time consuming, but only needs to be done once for each KDE model, 
# so we don't need to recompute p_model(data) over and over again when the 
# observation values aren't going to change. 
# Lower the number of samples per observation to speed this up.
if verbose:
    print("Freezing sample evaluations in their respective models...")
for model in model_names:
    if verbose:
        print("  {0:s}".format(model))
    getFromDict(kde_models, model.split('/')).freeze(obsdata)
if verbose:
    print("Done freezing KDE evaluations of observations!\n")



# ---  Copy kde_models so that they all have the same levels of hyperparameters
all_models_at_deepest = all([len(x.split('/')[1:])==Nhyper for x in model_names])
while all_models_at_deepest==False:
    # loop until all models have the same length
    for model in model_names:
        # See number of hyperparameters in model, subtract one for channel
        Nhyper_in_model = len(model.split('/'))-1
        kde_hold = getFromDict(kde_models, model.split('/'))
        # loop until this model has all the hyperparam levels as well
        while Nhyper_in_model < Nhyper:
            # remove kde model from old level
            setInDict(kde_models, model.split('/'), {})
            model_names.remove(model)
            for new_hyperparam in hyperparam_dict[Nhyper_in_model]:
                # copy the same kde model for the higher hyperparam level
                new_kde = deepcopy(kde_hold)
                new_level = model.split('/') + [new_hyperparam]
                setInDict(kde_models, new_level, new_kde)
                # add new model name
                model_names.append(model+'/'+new_hyperparam)
            Nhyper_in_model += 1
        model_names.sort()
    # see if all models are at deepest level else repeat
    all_models_at_deepest = all([len(x.split('/')[1:])==Nhyper for x in model_names])


# --- Do the sampling!

sampler = sample.Sampler(model_names)
sampler.sample(kde_models, obsdata, verbose=verbose)
samples = sampler.samples
lnprb = sampler.lnprb
submodels_dict = sampler.submodels_dict

# take the floor of the hyperparameters to get the model indices
for hyper_idx in list(submodels_dict.keys()):
    samples[:,:,hyper_idx] = np.floor(samples[:,:,hyper_idx]).astype(int)

# FIXME: need to get the conversion factors working
"""# get the conversion factors for a given submodel to normalize to unity so we can convert betas from detectable populations to underlying populations
print('Converting from detectable branching fractions to underlying brancing fractions...\n')
samples_detectable = samples.copy()
smdls = sorted(list(set([x.split('/',1)[1] for x in model_names])))
Nreweight=0
for smdl in smdls:
    convfac_per_smdl = []
    # get conversion factors
    for channel in channels:
        smdl_list = [channel] + smdl.split('/')
        convfac_per_smdl.append(getFromDict(kde_models, smdl_list).detectable_convfac)
    # normalize conversion factors and store in KDE objects
    #convfac_normed /= np.sum(convfac_normed)
    #for cidx, channel in enumerate(channels):
    #    smdl_list = [channel] + smdl.split('/')
    #    getFromDict(kde_models, smdl_list).detectable_convfac_normed = convfac_normed[cidx]
    # change the beta values in the posterior samples
    smdl_list = smdl.split('/')
    smdl_param_idxs = []
    for hyper_idx in np.arange(len(smdl_list)):
        smdl_param = submodels_dict[hyper_idx]
        smdl_param_idxs.append(list(smdl_param.values()).index(smdl_list[hyper_idx]))
    for i in np.arange(samples.shape[0]):
        for j in np.arange(samples.shape[1]):
            if samples[i,j,:len(smdl_param_idxs)] == smdl_param_idxs:
                Nreweight += 1
                samples[i,j,len(smdl_param_idxs):] /= convfac_per_smdl
                samples[i,j,len(smdl_param_idxs):] /= np.sum(samples[i,j,len(smdl_param_idxs):])

print(Nreweight)
print(samples.shape[0]*samples.shape[1])
samples = samples_detectable
"""

# Plot samples and histograms of betas per model
if make_plots==True:
    print("Plotting samples...\n")
    for hyper_idx in list(submodels_dict.keys()):
        msplot.plot_samples(samples, submodels_dict, model_names, channels, model0, name=args.name, hyper_idx=hyper_idx)


# reshape to have all steps from all walkers in a single dimension
samples = samples.reshape((samples.shape[0] * samples.shape[1], \
                                samples.shape[2]))
lnprb = lnprb.reshape((lnprb.shape[0] * lnprb.shape[1]))


# --- Print summary info about the sampling
if verbose:
    print("Sample breakdown:")
    recovered_vals = {}
    smdls = list(set([x.split('/',1)[1] for x in model_names]))
    for smdl in sorted(smdls):
        recovered_vals[smdl] = {}
        hyperparams = smdl.split('/')
        # loop over hyperparams to get matching samples
        for idx, param in enumerate(hyperparams):
            hyper_idx = list(submodels_dict[idx].keys())[list(submodels_dict[idx].values()).index(param)]
            if idx==0:
                matching_samps = samples[samples[:,idx] == hyper_idx]
            else:
                matching_samps = matching_samps[matching_samps[:,idx] == hyper_idx]
        # get counts in this model
        counts = matching_samps.shape[0]
        recovered_vals[smdl]['counts'] = counts
        # get betas for this model from each channel
        recovered_vals[smdl]['betas'] = {}
        for cidx, channel in enumerate(channels):
            # append beta values for this model
            if counts > 0:
                beta = matching_samps[:,Nhyper+cidx]
                beta = round(np.mean(beta), 2)
            else:
                beta = np.nan
            recovered_vals[smdl]['betas'][channel] = beta

    # print everything
    for smdl in sorted(smdls):
        counts = recovered_vals[smdl]['counts']
        betas = recovered_vals[smdl]['betas']
        print("  Model {0:s}: {1:d} samples, betas={2}".format(smdl, counts, list(betas.items())))
    print("")


# --- Save samples

if args.save_samples:
    if args.name:
        fname = "output_" + args.name + ".hdf5"
    else:
        fname = "output.hdf5"

    if verbose:
        print("Saving information to '{0:s}'...\n".format(fname))

    hfile = h5py.File(fname, "w")
    bsgrp = hfile.create_group("model_selection")

    # add model0 attribute
    if args.model0=='gwobs':
        info = np.append([str(args.model0)], [*events])
    else:
        info = np.append([str(args.model0)], \
            [*[key+': '+str(model0[key].rel_frac) for key in model0.keys()]])
    info = [x.encode('utf-8') for x in info]
    bsgrp.attrs["model0_params"] = info

    # add argument attribute
    arguments = []
    for key, val in vars(args).items():
        arguments.append('{}: {}'.format(key,val))
    bsgrp.attrs["args"] = arguments

    # add submodels_dict attribute
    for hyper_idx in submodels_dict.keys():
        conversion = []
        for key, val in submodels_dict[hyper_idx].items():
            conversion.append(str(key)+': '+str(val))
        bsgrp.attrs["p"+str(hyper_idx)+'_dict'] = conversion
    hfile.close()

    # save observations as dataframe
    df = pd.DataFrame()
    for idx, obs in enumerate(obsdata):
        df = df.append(pd.DataFrame(obs, columns=params, index=(idx*np.ones(len(obs)).astype(int))))
    df.to_hdf(fname, key='model_selection/obsdata')

    # save samples as dataframe
    columns = []
    convert_dict = {}
    for hyper_idx in submodels_dict.keys():
        columns.append('p'+str(hyper_idx))
        # save column names to convert model indices to ints
        convert_dict['p'+str(hyper_idx)] = int
    for channel in channels:
        columns.append('beta_'+channel)
    df = pd.DataFrame(samples, columns=columns).astype(convert_dict)
    df.to_hdf(fname, key='model_selection/samples')
