#!/usr/bin/env python

#######################
### MODEL SELECTION ###
#######################

# --- Import packages --- #
import sys
import argparse
import h5py
import warnings
from functools import reduce
import operator
from copy import deepcopy
import pdb

import numpy as np
import pandas as pd
import scipy.stats

from populations import bbh_models, gw_obs
from sample import sample
from plot import msplot

VERBOSE=True
MAKE_PLOTS=True

# --- Argument handling --- #
argp = argparse.ArgumentParser()
argp.add_argument("-f", "--file-path", type=str, required=True, help="Path to where the population models are living. Models should be stored in hdf5 format, with the channel as the base group, and model parameters as subgroups (e.g., 'CE/chi01/alpha0.5').")
argp.add_argument("-m", "--model0", type=str, required=True, help="Sets the 'true' model from which mock observations are drawn. When there are multiple parameters in the submodel, separate with '/' (e.g., 'chi00/alpha5'). If 'gwobs', will use the actual GW observations.")
argp.add_argument("-gw", "--gwpath", type=str, help="Sets the path for where the GW samples are living. Necessary if model0='gwobs'. Default=None.")
argp.add_argument("-c", "--specific-channels", nargs="+", help="Specifies the formation channels you wish to consider in the inference. If 'None', will use all channels in the hdf5 file. Default=None.")
argp.add_argument("-b", "--beta", nargs="*", help="Sets the branching fraction for mock observations. The number provided is the fraction of systems that come from each channel in alphabetical order. Must be set if gwobs not used. Can provide Nchannel values (which must sum to unity) or Nchannel-1 values (which must be less than 1.0, and the last branching fraction is inferred). Default=None.")
argp.add_argument("-p", "--params", nargs="+", default="mchirp", help="Specifies the parameters you wish to use in the inference. Default=mchirp.")
argp.add_argument("-n", "--Nobs", type=int, help="Number of mock observations to be taken from the mixture model. Must be set if gwobs not used. Default=None.")
argp.add_argument("-N", "--Nsamps", type=int, default=100, help="Number of samples to be drawn from the posterior distributions and used to construct the KDE models. Default=100.")
argp.add_argument("-w", "--weights", type=str, help="Name of column in dataframe of detection probabilities. This is used to construct a 'detection-weighted' kde. The weights have the same name as the network sensitivity from the LVC Observing Scenarios, and have '_network' appended if using a 3-detector configuration. Default=None.")
argp.add_argument("-u", "--uncertainty", type=str, help="Smear out observations in a mocked up attempt at non-delta function observation posteriors. For GW obs, you can choose to smear using the actual posterior samples ('posteriors'), or from a mock gaussian with the mean and sigma of observations ('gaussian'). For mock observations, you can choose to smear according to the average spread in parameters from current GW observations ('gwevents'), or use a gaussian with an SNR-dependent sigma ('snr'). Default=None.")
argp.add_argument("-rp", "--rate-prior", action="store_true", help="Uses predicted rates from population models as priors. WARNING: still in beta. Default=False.")
argp.add_argument("-sm", "--spinmag", type=str, help="Define the spin magnitude distribution you wish to use. Required for using spin parameters in populations where the spin magnitude is not specified. Default is None.")
argp.add_argument("-S", "--save-samples", action="store_true", help="Save all the samples rather than just the summary statistics. Default is False.")
argp.add_argument("-E", "--evidence", action="store_true", help="Determines whether or not to calculate the evidence for each submodel using thermodynamic integration. WARNING: still in beta. Default is False.")
argp.add_argument("-rs", "--random-seed", type=int, help="Use this to set the random seed. Default=None.")
argp.add_argument("--name", type=str, help="Use this as the stem for all file output. Default=None.")
args = argp.parse_args()

# --- Set random seed
if args.random_seed:
    np.random.seed(args.random_seed)

# --- Useful functions for accessing items in dictionary
def getFromDict(dataDict, mapList):
    return reduce(operator.getitem, mapList, dataDict)
def setInDict(dataDict, mapList, value):
    getFromDict(dataDict, mapList[:-1])[mapList[-1]] = value

# --- Load in models/kdemodels into dict structure: models[model][channel]
model_names, models, kde_models, kde_models_unweighted = bbh_models.get_models(args.file_path, args.specific_channels, args.params, args.spinmag, weighting=args.weights)
model_names.sort()
channels = sorted(list(models.keys()))
params = args.params
hyperparams = list(set([x.split('/', 1)[1] for x in model_names]))
Nhyper = np.max([len(x.split('/')) for x in hyperparams])

# see if we're using GW observations
gwobs = True if args.model0=='gwobs' else False

if VERBOSE:
    print("")
    print("Formation channels: " + ", ".join(channels))
    print("Astrophysical models: " + ", ".join(model_names))
    print("Parameters for inference: " + ", ".join(params))
    print("")



# --- Perform some checks to make sure things are compatible

# check that a value of beta is provided if gwobs not specified
if not gwobs:
    if not args.beta:
        raise ValueError("You need to either specify branching fractions or choose to instead use GW observations!")

# check that the true model provided is valid if gwobs not specified
for channel in channels:
    channel_smdls = [s.split('/', 1)[1] for s in model_names if channel+'/' in s]
    if (args.model0 not in channel_smdls and not gwobs):
        raise ValueError("The true model you specified ({0:s}) is not one of the models in {1:s} directory!".format(args.model0, args.file_path))

# ensure that the number of hyperparameters in each channel is the same depth
for channel in channels:
    channel_smdls = [x for x in model_names if channel+'/' in x]
    Nlevels_in_channel = [len(x.split('/')) for x in channel_smdls]
    if not all(x == Nlevels_in_channel[0] for x in Nlevels_in_channel):
        raise ValueError("The formation channel '{0:s}' does not have the same hierarchical levels of hyperparameters across submodels: {1:s}".format(channel, ','.join(channel_smdls)))

# ensure that models at each level are consistent across formation channels
i=1 #start at 1, which will be the highest-level hyperparameter since the formation channel is the first parameter
while i <= Nhyper:
    hyper_set = list(set([x.split('/')[i] for x in model_names]))
    for channel in channels:
        channel_smdls = [x for x in model_names if channel+'/' in x]
        Nlevels_in_channel = [len(x.split('/')) for x in channel_smdls][0]-1
        if Nlevels_in_channel <= i:
            channel_set = [x.split('/')[i] for x in channel_smdls]
            if sorted(hyper_set) != sorted(channel_set):
                raise ValueError("At hyperparameter level {0:d}, the formation channel {1:s} does not have the same hyperparameters as the rest of the models (all models: {2:s}, {1:s}: {3:s}".format(i, channel, ','.join(hyper_set), ','.join(channel_set)))
    i += 1

# check that Nobs was specified if not using gwobs
if not gwobs and not args.Nobs:
    raise ValueError("You need to specify and number of observations to be drawn from the 'true' model if not using GW observations!")

# check that valid measurement uncertainty is specified
if gwobs:
    valid_uncertainties = ["gaussian", "posteriors"]
    if args.uncertainty not in valid_uncertainties:
        raise ValueError("Unspecified measurement uncertainty procedure when using GW observations: '{0:s}' (valid uncertainties: {1:s})".format(args.uncertainty, ', '.join(valid_uncertainties)))
else:
    valid_uncertainties = ["gwevents", "snr"]
    if args.uncertainty not in valid_uncertainties:
        raise ValueError("Unspecified measurement uncertainty procedure when using mock observations: '{0:s}' (valid uncertainties: {1:s})".format(args.uncertainty, ', '.join(valid_uncertainties)))

# parse the branching ratio values and check for errors
if not gwobs:
    betas = [float(x) for x in args.beta]
    if (len(betas) != len(channels)) and (len(betas) != len(channels)-1):
        raise ValueError("Must specify {0:d} or {1:d} branching fractions, you provided {2:d}!".format(len(channels)-1, len(channels), len(betas)))
    if np.sum(betas) > 1.0:
        raise ValueError("Branching fractions must sum to less than or equal to 1.0, yours sum to {0:0.2f}!".format(np.sum(betas)))
    if (len(betas) == len(channels)) and (np.sum(betas) != 1.0):
        raise ValueError("If you provide the same number of branching fractions as channels, they must sum to exactly 1.0 (yours sum to {0:0.2f})!".format(np.sum(betas)))

    if len(betas) != len(channels):
        betas.append(1.0 - np.sum(betas))

# --- If model0 specified, save relative fractions for each KDE model, and store model0
if not gwobs:
    if VERBOSE:
        print("Saving relative fractions and storing true model...\n")

    model0 = {}
    # since channels are sorted alphabetically, branching fractions are defined in the same order
    for idx, channel in enumerate(channels):
        channel_mdls = [x for x in model_names if channel+'/' in x]
        for model in channel_mdls:
            smdl = model.split('/',1)[1]
            beta = betas[channels.index(channel)]
            # store relative fraction
            getFromDict(kde_models, model.split('/')).rel_frac(beta)
            # print info about model0
            if (smdl == args.model0):
                model0[channel] = getFromDict(kde_models, model.split('/'))
                if VERBOSE:
                    if idx==0:
                        print("'{0:s}' set as true model".format(smdl))
                        print("  model range:")
                    print("    {0:s} (beta={1:0.2f})".format(channel, beta))
                    for param in args.params:
                        print("      {0:s}: {1:0.2f} - {2:0.2f}".format(param,\
                                getFromDict(models, model.split('/'))[param].min(),\
                                getFromDict(models, model.split('/'))[param].max()))
                    if idx==len(betas)-1:
                        print("")

# --- Generate observations ([observations, params, samples])
if VERBOSE:
    print("Generating observations...\n")

# Calls gw_obs.py if argument is passed
if gwobs:
    model0=None
    obsdata, events = gw_obs.generate_observations(params, args.gwpath, \
                                            args.Nsamps, args.uncertainty)
    if VERBOSE:
        print("Using the following {0:d} GW observations for \
inference:".format(len(events)))
        print(*events, sep=', ')
        print("")

else:
    if VERBOSE:
        print("Drawing {0:d} observations from the true \
model...\n".format(int(args.Nobs)))
    for idx, channel in enumerate(model0):
        # first check that the branching fractions * Nobs are integers
        if not (args.Nobs*model0[channel]._rel_frac).is_integer():
            warnings.warn('Number of observations is not divisble by branching fractions, this may result in drawing a number of samples slighty different than what was specified!')
        if idx==0:
            Nobs_per_channel = int(np.round(args.Nobs * model0[channel]._rel_frac))
            obsdata = model0[channel].generate_observations(Nobs_per_channel, \
                                                args.Nsamps, args.uncertainty)
        else:
            Nobs_per_channel = int(np.round(args.Nobs * model0[channel]._rel_frac))
            obsdata = np.concatenate((obsdata, \
                  model0[channel].generate_observations(Nobs_per_channel, \
                                            args.Nsamps, args.uncertainty)))


# Plot the KDEs and observations
if MAKE_PLOTS==True:
    print("Plotting marginalized KDE models...")
    msplot.plot_1D_kdemodels(model_names, kde_models, params, obsdata, model0, \
                name=args.name, fixed_vals=[], plot_obs=True, plot_obs_samples=False)
    print("")


# --- Freeze sample evaluations in each model. 
# This is time consuming, but only needs to be done once for each KDE model, 
# so we don't need to recompute p_model(data) over and over again when the 
# observation values aren't going to change. 
# Lower the number of samples per observation to speed this up.
if VERBOSE:
    print("Freezing sample evaluations in their respective models...")
for model in model_names:
    if VERBOSE:
        print("  {0:s}".format(model))
    getFromDict(kde_models, model.split('/')).freeze(obsdata)
if VERBOSE:
    print("Done freezing KDE evaluations of observations!\n")



# ---  Copy models so that they all have the same levels of hyperparameters

# FIXME: Once I have the alpha models, do this!

# --- Do the sampling!

sampler = sample.Sampler(model_names)
sampler.sample(kde_models, obsdata)
samples = sampler.samples
lnprb = sampler.lnprb
submodels_dict = sampler.submodels_dict

# take the floor of the hyperparameters to get the model indices
for hyper_idx in list(submodels_dict.keys()):
    samples[:,:,hyper_idx] = np.floor(samples[:,:,hyper_idx]).astype(int)


# Plot samples and histograms of betas per model
if MAKE_PLOTS==True:
    print("Plotting samples...\n")
    msplot.plot_samples(samples, submodels_dict, model_names, channels, model0, name=args.name, hyper_idx=0)


# reshape to have all steps from all walkers in a single dimension
# (note that we added a dim for the last beta that we synthesized)
samples = samples.reshape((samples.shape[0] * samples.shape[1], \
                                samples.shape[2]))
lnprb = lnprb.reshape((lnprb.shape[0] * lnprb.shape[1]))


# --- Print summary info about the sampling
if VERBOSE:
    print("Sample breakdown:")
    recovered_vals = {}
    smdls = list(set([x.split('/',1)[1] for x in model_names]))
    for smdl in sorted(smdls):
        recovered_vals[smdl] = {}
        hyperparams = smdl.split('/')
        # loop over hyperparams to get matching samples
        for idx, param in enumerate(hyperparams):
            hyper_idx = list(submodels_dict[idx].keys())[list(submodels_dict[idx].values()).index(param)]
            if idx==0:
                matching_samps = samples[samples[:,idx] == hyper_idx]
            else:
                matching_samps = matchin_samps[matching_samps[:,idx] == hyper_idx]
        # get counts in this model
        counts = matching_samps.shape[0]
        recovered_vals[smdl]['counts'] = counts
        # get betas for this model from each channel
        recovered_vals[smdl]['betas'] = {}
        for cidx, channel in enumerate(channels):
            # append beta values for this model
            if counts > 0:
                beta = matching_samps[:,Nhyper+cidx]
                beta = round(np.mean(beta), 2)
            else:
                beta = np.nan
            recovered_vals[smdl]['betas'][channel] = beta

    # print everything
    for smdl in sorted(smdls):
        counts = recovered_vals[smdl]['counts']
        betas = recovered_vals[smdl]['betas']
        print("  Model {0:s}: {1:d} samples, betas={2}".format(smdl, counts, list(betas.items())))
    print("")


# --- Save samples

if args.save_samples:
    if args.name:
        fname = "output_" + args.name + ".hdf5"
    else:
        fname = "output.hdf5"

    if VERBOSE:
        print("Saving information to '{0:s}'...\n".format(fname))

    hfile = h5py.File(fname, "w")
    bsgrp = hfile.create_group("model_selection")

    # add model0 attribute
    if args.model0=='gwobs':
        info = np.append([str(args.model0)], [*events])
    else:
        info = np.append([str(args.model0)], \
            [*[key+': '+str(model0[key]._rel_frac) for key in model0.keys()]])
    info = [x.encode('utf-8') for x in info]
    bsgrp.attrs["model0_params"] = info

    # add argument attribute
    arguments = []
    for key, val in vars(args).items():
        arguments.append('{}: {}'.format(key,val))
    bsgrp.attrs["args"] = arguments

    # add submodels_dict attribute
    for hyper_idx in submodels_dict.keys():
        conversion = []
        for key, val in submodels_dict[hyper_idx].items():
            conversion.append(str(key)+': '+str(val))
        bsgrp.attrs["p"+str(hyper_idx)+'_dict'] = conversion
    hfile.close()

    # save observations as dataframe
    df = pd.DataFrame()
    for idx, obs in enumerate(obsdata):
        df = df.append(pd.DataFrame(obs, columns=params, index=(idx*np.ones(len(obs)).astype(int))))
    df.to_hdf(fname, key='model_selection/obsdata')

    # save samples as dataframe
    columns = []
    convert_dict = {}
    for hyper_idx in submodels_dict.keys():
        columns.append('p'+str(hyper_idx))
        # save column names to convert model indices to ints
        convert_dict['p'+str(hyper_idx)] = int
    for channel in channels:
        columns.append('beta_'+channel)
    df = pd.DataFrame(samples, columns=columns).astype(convert_dict)
    df.to_hdf(fname, key='model_selection/samples')
